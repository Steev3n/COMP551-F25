{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9V9UODBoVPh",
        "outputId": "e0212db5-09d7-4288-e596-152451dc370e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 278kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.05MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.43MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 375\n",
            "Validation batches: 94\n",
            "Test batches: 79\n",
            "Computed mean: 0.2860, std: 0.3530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image tensor shape: torch.Size([128, 1, 28, 28])\n",
            "Batch labels tensor shape: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def compute_fashion_mnist_mean_std(root=\"./data\"):\n",
        "    \"\"\"\n",
        "    Load raw FashionMNIST training data, convert to float in [0,1],\n",
        "    and compute global mean and std over all pixels, as recommended in CS231n:\n",
        "    center data to mean 0 and normalize its scale.\n",
        "    \"\"\"\n",
        "    # Load once without transforms to access raw uint8 data\n",
        "    raw_train = datasets.FashionMNIST(\n",
        "        root=root,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=None\n",
        "    )\n",
        "\n",
        "    # raw_train.data: shape [60000, 28, 28], dtype uint8 in [0, 255]\n",
        "    train_data = raw_train.data.float() / 255.0 # match ToTensor scaling\n",
        "\n",
        "    mean = train_data.mean().item()\n",
        "    std = train_data.std().item()\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "def get_fashion_mnist_datasets(root=\"./data\", val_ratio=0.2, seed=551):\n",
        "    \"\"\"\n",
        "    Acquire FashionMNIST, compute normalization statistics on training set,\n",
        "    and return normalized train, validation, and test datasets.\n",
        "\n",
        "    - Uses the default 28x28 version.\n",
        "    - Uses the 60k official training split for train + validation.\n",
        "    - Uses the 10k official test split as test.\n",
        "    \"\"\"\n",
        "    mean, std = compute_fashion_mnist_mean_std(root)\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # [0, 255] -> [0, 1]\n",
        "        transforms.Normalize((mean,), (std,)) # zero mean, unit-ish variance\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((mean,), (std,))\n",
        "    ])\n",
        "\n",
        "    full_train_dataset = datasets.FashionMNIST(\n",
        "        root=root,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset = datasets.FashionMNIST(\n",
        "        root=root,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Split 60k training samples into train and validation\n",
        "    total_train = len(full_train_dataset) # should be 60000\n",
        "    val_size = int(val_ratio * total_train)\n",
        "    train_size = total_train - val_size\n",
        "\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    train_dataset, val_dataset = random_split(\n",
        "        full_train_dataset,\n",
        "        [train_size, val_size],\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, mean, std\n",
        "\n",
        "\n",
        "def get_fashion_mnist_loaders(\n",
        "    root=\"./data\",\n",
        "    val_ratio=0.2,\n",
        "    batch_size=128,\n",
        "    num_workers=2,\n",
        "    seed=551\n",
        "):\n",
        "    \"\"\"\n",
        "    Convenience function that wraps dataset acquisition and returns\n",
        "    DataLoaders for train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    train_dataset, val_dataset, test_dataset, mean, std = get_fashion_mnist_datasets(\n",
        "        root=root,\n",
        "        val_ratio=val_ratio,\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader, mean, std\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_loader, val_loader, test_loader, mean, std = get_fashion_mnist_loaders()\n",
        "\n",
        "    print(f\"Train batches: {len(train_loader)}\")\n",
        "    print(f\"Validation batches: {len(val_loader)}\")\n",
        "    print(f\"Test batches: {len(test_loader)}\")\n",
        "    print(f\"Computed mean: {mean:.4f}, std: {std:.4f}\")\n",
        "\n",
        "    # Inspect one batch shape\n",
        "    images, labels = next(iter(train_loader))\n",
        "    # images shape: [batch_size, 1, 28, 28]\n",
        "    print(f\"Batch image tensor shape: {images.shape}\")\n",
        "    print(f\"Batch labels tensor shape: {labels.shape}\")\n"
      ]
    }
  ]
}